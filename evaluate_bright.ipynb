{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6744811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating biology split: 100%|██████████| 103/103 [00:00<00:00, 28562.86 examples/s]\n",
      "Generating earth_science split: 100%|██████████| 116/116 [00:00<00:00, 45603.08 examples/s]\n",
      "Generating economics split: 100%|██████████| 103/103 [00:00<00:00, 38490.14 examples/s]\n",
      "Generating psychology split: 100%|██████████| 101/101 [00:00<00:00, 36782.56 examples/s]\n",
      "Generating robotics split: 100%|██████████| 101/101 [00:00<00:00, 47646.46 examples/s]\n",
      "Generating stackoverflow split: 100%|██████████| 117/117 [00:00<00:00, 44470.65 examples/s]\n",
      "Generating sustainable_living split: 100%|██████████| 108/108 [00:00<00:00, 34471.11 examples/s]\n",
      "Generating pony split: 100%|██████████| 112/112 [00:00<00:00, 53188.64 examples/s]\n",
      "Generating leetcode split: 100%|██████████| 142/142 [00:00<00:00, 44767.83 examples/s]\n",
      "Generating aops split: 100%|██████████| 111/111 [00:00<00:00, 6899.55 examples/s]\n",
      "Generating theoremqa_theorems split: 100%|██████████| 76/76 [00:00<00:00, 30183.42 examples/s]\n",
      "Generating theoremqa_questions split: 100%|██████████| 194/194 [00:00<00:00, 11264.55 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "bright_biology = load_dataset('xlangai/BRIGHT', 'examples')['biology']\n",
    "print(len(bright_biology))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba5447",
   "metadata": {},
   "source": [
    "## Let's try to evaluate BRIGHT benchmark using MTEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4df12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating biology split: 100%|██████████| 57359/57359 [00:00<00:00, 484457.45 examples/s]\n",
      "Generating earth_science split: 100%|██████████| 121249/121249 [00:00<00:00, 1374718.64 examples/s]\n",
      "Generating economics split: 100%|██████████| 50220/50220 [00:00<00:00, 1350390.41 examples/s]\n",
      "Generating psychology split: 100%|██████████| 52835/52835 [00:00<00:00, 2748977.25 examples/s]\n",
      "Generating robotics split: 100%|██████████| 61961/61961 [00:00<00:00, 1565099.88 examples/s]\n",
      "Generating stackoverflow split: 100%|██████████| 107081/107081 [00:00<00:00, 360565.04 examples/s]\n",
      "Generating sustainable_living split: 100%|██████████| 60792/60792 [00:00<00:00, 2350263.88 examples/s]\n",
      "Generating pony split: 100%|██████████| 7894/7894 [00:00<00:00, 1191730.04 examples/s]\n",
      "Generating leetcode split: 100%|██████████| 413932/413932 [00:00<00:00, 1299825.89 examples/s]\n",
      "Generating aops split: 100%|██████████| 188177/188177 [00:00<00:00, 2053277.20 examples/s]\n",
      "Generating theoremqa_theorems split: 100%|██████████| 23839/23839 [00:00<00:00, 1472555.82 examples/s]\n",
      "Generating theoremqa_questions split: 100%|██████████| 188177/188177 [00:00<00:00, 2033376.99 examples/s]\n",
      "Generating biology split: 100%|██████████| 103/103 [00:00<00:00, 25534.21 examples/s]\n",
      "Generating earth_science split: 100%|██████████| 116/116 [00:00<00:00, 39929.36 examples/s]\n",
      "Generating economics split: 100%|██████████| 103/103 [00:00<00:00, 44514.51 examples/s]\n",
      "Generating psychology split: 100%|██████████| 101/101 [00:00<00:00, 30382.61 examples/s]\n",
      "Generating robotics split: 100%|██████████| 101/101 [00:00<00:00, 31055.25 examples/s]\n",
      "Generating stackoverflow split: 100%|██████████| 117/117 [00:00<00:00, 19759.76 examples/s]\n",
      "Generating sustainable_living split: 100%|██████████| 108/108 [00:00<00:00, 21582.01 examples/s]\n",
      "Generating pony split: 100%|██████████| 112/112 [00:00<00:00, 29015.57 examples/s]\n",
      "Generating leetcode split: 100%|██████████| 142/142 [00:00<00:00, 32854.76 examples/s]\n",
      "Generating aops split: 100%|██████████| 111/111 [00:00<00:00, 5897.07 examples/s]\n",
      "Generating theoremqa_theorems split: 100%|██████████| 65/65 [00:00<00:00, 14418.75 examples/s]\n",
      "Generating theoremqa_questions split: 100%|██████████| 206/206 [00:00<00:00, 15364.02 examples/s]\n",
      "Generating biology split: 100%|██████████| 524/524 [00:00<00:00, 5363.86 examples/s]\n",
      "Generating earth_science split: 100%|██████████| 601/601 [00:00<00:00, 9417.23 examples/s]\n",
      "Generating economics split: 100%|██████████| 516/516 [00:00<00:00, 22289.22 examples/s]\n",
      "Generating psychology split: 100%|██████████| 512/512 [00:00<00:00, 37479.21 examples/s]\n",
      "Generating robotics split: 100%|██████████| 508/508 [00:00<00:00, 44379.55 examples/s]\n",
      "Generating stackoverflow split: 100%|██████████| 1858/1858 [00:00<00:00, 9178.02 examples/s]\n",
      "Generating sustainable_living split: 100%|██████████| 554/554 [00:00<00:00, 7456.25 examples/s]\n",
      "Generating pony split: 100%|██████████| 577/577 [00:00<00:00, 80415.80 examples/s]\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb483f6a5233a6efc2d63d71540a4443dfb/.huggingface.yaml\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb483f6a5233a6efc2d63d71540a4443dfb/.huggingface.yaml\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb483f6a5233a6efc2d63d71540a4443dfb/.huggingface.yaml\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb483f6a5233a6efc2d63d71540a4443dfb/.huggingface.yaml\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb483f6a5233a6efc2d63d71540a4443dfb/.huggingface.yaml\n",
      "Retrying in 8s [Retry 5/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb483f6a5233a6efc2d63d71540a4443dfb/.huggingface.yaml\n",
      "Using the latest cached version of the dataset since xlangai/BRIGHT couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'long_documents' at /Users/abdulhakeemadefioye/.cache/huggingface/datasets/xlangai___bright/long_documents/0.0.0/a75a0eb483f6a5233a6efc2d63d71540a4443dfb (last modified on Sat Jun  7 22:56:06 2025).\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb/README.md\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb/README.md\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb/README.md\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb/README.md\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb/README.md\n",
      "Retrying in 8s [Retry 5/5].\n"
     ]
    }
   ],
   "source": [
    "import mteb\n",
    "\n",
    "\n",
    "tasks = mteb.get_tasks(tasks=[\"BrightRetrieval\"])\n",
    "tasks\n",
    "tasks[0].load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b311418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m            BrightRetrieval\n",
      "\u001b[0;31mString form:\u001b[0m     BrightRetrieval(name='BrightRetrieval', languages=['eng'])\n",
      "\u001b[0;31mFile:\u001b[0m            /opt/anaconda3/envs/pylate-experiment/lib/python3.10/site-packages/mteb/tasks/Retrieval/eng/BrightRetrieval.py\n",
      "\u001b[0;31mSource:\u001b[0m         \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mBrightRetrieval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultilingualTask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAbsTaskRetrieval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaskMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BrightRetrieval\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"path\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"xlangai/BRIGHT\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"revision\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"a75a0eb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://huggingface.co/datasets/xlangai/BRIGHT\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Bright retrieval dataset.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Retrieval\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"s2p\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0meval_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"standard\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0meval_langs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDOMAINS_langs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmain_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ndcg_at_10\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2024-03-01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2024-06-01\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdomains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Non-fiction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Written\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtask_subtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Article retrieval\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mlicense\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cc-by-4.0\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mannotations_creators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"derived\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdialect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msample_creation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"found\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodalities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mbibtex_citation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr\"\"\"\u001b[0m\n",
      "\u001b[0;34m@misc{su2024brightrealisticchallengingbenchmark,\u001b[0m\n",
      "\u001b[0;34m  archiveprefix = {arXiv},\u001b[0m\n",
      "\u001b[0;34m  author = {Hongjin Su and Howard Yen and Mengzhou Xia and Weijia Shi and Niklas Muennighoff and Han-yu Wang and Haisu Liu and Quan Shi and Zachary S. Siegel and Michael Tang and Ruoxi Sun and Jinsung Yoon and Sercan O. Arik and Danqi Chen and Tao Yu},\u001b[0m\n",
      "\u001b[0;34m  eprint = {2407.12883},\u001b[0m\n",
      "\u001b[0;34m  primaryclass = {cs.CL},\u001b[0m\n",
      "\u001b[0;34m  title = {BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval},\u001b[0m\n",
      "\u001b[0;34m  url = {https://arxiv.org/abs/2407.12883},\u001b[0m\n",
      "\u001b[0;34m  year = {2024},\u001b[0m\n",
      "\u001b[0;34m}\u001b[0m\n",
      "\u001b[0;34m\"\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mload_bright_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_bright_data\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mload_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClass docstring:\u001b[0m\n",
      "Abstract class for retrieval experiments.\n",
      "\n",
      "Child-classes must implement the following properties:\n",
      "\n",
      "self.corpus: dict[str, dict[str, str]]\n",
      "    Semantically, it should contain dict[split_name, dict[sample_id, dict[str, str]]]\n",
      "    E.g. {\"test\": {\"document_one\": {\"_id\": \"d1\", \"title\": \"title\", \"text\": \"text\"}}}\n",
      "\n",
      "self.queries: dict[str, dict[str, Union[str, list[str]]]]\n",
      "    Semantically, it should contain dict[split_name, dict[sample_id, str]] or dict[split_name, dict[sample_id, list[str]]] for conversations\n",
      "    E.g. {\"test\": {\"q1\": \"query\"}}\n",
      "    or {\"test\": {\"q1\": [\"turn1\", \"turn2\", \"turn3\"]}}\n",
      "\n",
      "self.relevant_docs: dict[str, dict[str, dict[str, int]]]\n",
      "    Semantically, it should contain dict[split_name, dict[sample_id, dict[doc_id, score]]]\n",
      "    E.g.: {\"test\": {\"q1\": {\"document_one\": 1}}}"
     ]
    }
   ],
   "source": [
    "tasks[0]??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86d3746b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['biology', 'earth_science', 'economics', 'psychology', 'robotics', 'stackoverflow', 'sustainable_living', 'pony', 'leetcode', 'aops', 'theoremqa_theorems', 'theoremqa_questions'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tasks[0].queries.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f80e017d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57359"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks[0].corpus[\"biology\"][\"standard\"].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "461adae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb/README.md\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb/README.md\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb/README.md\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb/README.md\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb/README.md\n",
      "Retrying in 8s [Retry 5/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb/README.md\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb483f6a5233a6efc2d63d71540a4443dfb/BRIGHT.py\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb483f6a5233a6efc2d63d71540a4443dfb/BRIGHT.py\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb483f6a5233a6efc2d63d71540a4443dfb/BRIGHT.py\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/datasets/xlangai/BRIGHT/resolve/a75a0eb483f6a5233a6efc2d63d71540a4443dfb/BRIGHT.py\n",
      "Retrying in 8s [Retry 4/5].\n",
      "^C\n",
      "  File \"/opt/anaconda3/envs/pylate-experiment/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/pylate-experiment/lib/python3.10/site-packages/huggingface_hub/hf_api.py\", line 5486, in hf_hub_download\n",
      "    return hf_hub_download(\n",
      "  File \"/opt/anaconda3/envs/pylate-experiment/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/pylate-experiment/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1008, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "  File \"/opt/anaconda3/envs/pylate-experiment/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1071, in _hf_hub_download_to_cache_dir\n",
      "    (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = _get_metadata_or_catch_error(\n",
      "  File \"/opt/anaconda3/envs/pylate-experiment/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1533, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(\n",
      "  File \"/opt/anaconda3/envs/pylate-experiment/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/pylate-experiment/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 1450, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "  File \"/opt/anaconda3/envs/pylate-experiment/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 286, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "  File \"/opt/anaconda3/envs/pylate-experiment/lib/python3.10/site-packages/huggingface_hub/file_download.py\", line 309, in _request_wrapper\n",
      "    response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(429,))\n",
      "  File \"/opt/anaconda3/envs/pylate-experiment/lib/python3.10/site-packages/huggingface_hub/utils/_http.py\", line 333, in http_backoff\n",
      "    time.sleep(sleep_time)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python evaluate_bright.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd001479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pylate-experiment)",
   "language": "python",
   "name": "pylate-experiment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
